import torch
import cv2
import numpy as np
import time
# ç¡®ä¿å¯¼å…¥åå’Œä½ çš„ä¸€è‡´
from train_vqvae_256 import VQVAE, DEVICE 
from train_world_model import WorldModelGPT, BLOCK_SIZE

# ================= é…ç½® =================
VQVAE_PATH = "checkpoints_vqvae_256/vqvae_256_ep99.pth"
# ğŸ”´ è¯•ç€æ¢ä¸€ä¸ªç¨å¾®æ—©ä¸€ç‚¹çš„ GPT æƒé‡ï¼Œä¸è¦ç”¨ Loss < 1 çš„é‚£ä¸ª
WORLD_MODEL_PATH = "checkpoints_world_model/world_model_ep10.pth" # ä¸¾ä¾‹ï¼Œè¯·ä¿®æ”¹

# ğŸ”´ å…³é”®è°ƒæ•´ï¼šæåº¦ä¿å®ˆçš„å‚æ•°
TEMPERATURE = 0.1  # æä½æ¸©åº¦
TOP_K = 5          # åªçœ‹å‰5å

def load_models():
    print(f"â³ Loading GPT from {WORLD_MODEL_PATH}...")
    gpt = WorldModelGPT().to(DEVICE)
    # ä½¿ç”¨ weights_only=False å¿½ç•¥è­¦å‘Š
    gpt.load_state_dict(torch.load(WORLD_MODEL_PATH, map_location=DEVICE, weights_only=False)["model"])
    gpt.eval()
    
    print(f"â³ Loading VQ-VAE from {VQVAE_PATH}...")
    vqvae = VQVAE().to(DEVICE)
    vqvae.load_state_dict(torch.load(VQVAE_PATH, map_location=DEVICE, weights_only=False)["model"])
    vqvae.eval()
    return vqvae, gpt

def decode_indices(vqvae, indices):
    with torch.no_grad():
        indices_tensor = torch.LongTensor(indices).unsqueeze(0).to(DEVICE)
        z_q = vqvae.quantizer.embedding(indices_tensor).permute(0, 3, 1, 2)
        decoded_img = vqvae.decoder(z_q)
        img = decoded_img[0].cpu().permute(1, 2, 0).numpy()
        # å½’ä¸€åŒ–ä¿®å¤ï¼šç¡®ä¿èŒƒå›´åœ¨ 0-255
        img = (img - img.min()) / (img.max() - img.min() + 1e-5) * 255.0
        return img.astype(np.uint8)

def main():
    vqvae, gpt = load_models()
    
    # æ‰‹åŠ¨é€ ä¸€ä¸ªç®€å•çš„å¯åŠ¨ Token (æ¨¡æ‹Ÿå…¨é»‘æˆ–ç®€å•çš„èµ·æ­¥)
    # è¿™é‡Œæˆ‘ä»¬éšæœºç”Ÿæˆä¸€ä¸ªèµ·å§‹å¸§ï¼Œçœ‹çœ‹èƒ½ä¸èƒ½å˜æˆæœ‰æ„ä¹‰çš„ä¸œè¥¿
    # æˆ–è€…ç”¨å…¨ 0 (å‡è®¾ 0 æ˜¯å¤©ç©º/èƒŒæ™¯)
    current_tokens = torch.randint(0, 100, (1, 1, 256)).to(DEVICE) # éšæœºå™ªå£°å¯åŠ¨
    
    # æ¨¡æ‹Ÿâ€œä¸€ç›´è¸©æ²¹é—¨â€çš„åŠ¨ä½œ
    # åŠ¨ä½œ (1, 1, 2) -> [è½¬å‘0, æ²¹é—¨1]
    current_actions = torch.tensor([[[0.0, 1.0]]]).to(DEVICE)

    print("ğŸš€ å¼€å§‹è°ƒè¯•ç”Ÿæˆ (ç”Ÿæˆ 1 å¸§)...")
    
    with torch.no_grad():
        # æ„é€ è¾“å…¥
        pred_tokens_so_far = torch.zeros((1, 1, 256), dtype=torch.long).to(DEVICE)
        full_input_tokens = torch.cat([current_tokens, pred_tokens_so_far], dim=1)
        full_input_actions = torch.cat([current_actions, current_actions], dim=1) # åŠ¨ä½œé‡å¤

        # é€åƒç´ ç”Ÿæˆ
        generated_indices = []
        for i in range(16): # åªç”Ÿæˆå‰ 16 ä¸ªåƒç´ çœ‹çœ‹
            logits, _ = gpt(full_input_tokens, full_input_actions)
            
            # è·å–å½“å‰ä½ç½®çš„é¢„æµ‹
            # ä¸Šä¸‹æ–‡é•¿åº¦ 1å¸§(257) + å½“å‰ç¬¬iä¸ª
            target_idx = 1 * 257 + i - 1
            next_token_logits = logits[:, target_idx, :] / TEMPERATURE
            
            # Top-K é‡‡æ ·
            v, _ = torch.topk(next_token_logits, TOP_K)
            next_token_logits[next_token_logits < v[:, [-1]]] = -float('Inf')
            probs = torch.nn.functional.softmax(next_token_logits, dim=-1)
            idx = torch.multinomial(probs, num_samples=1)
            
            val = idx.item()
            generated_indices.append(val)
            print(f"åƒç´  {i}: é¢„æµ‹ Token ID = {val}")

    print(f"\nğŸ“Š é¢„æµ‹çš„å‰16ä¸ª Token: {generated_indices}")
    print("ğŸ‘‰ å¦‚æœè¿™äº›æ•°å­—å…¨æ˜¯åŒä¸€ä¸ªæ•° (å¦‚ 0,0,0) -> æ¨¡å¼å´©å¡Œ (Mode Collapse)")
    print("ğŸ‘‰ å¦‚æœè¿™äº›æ•°å­—éå¸¸éšæœºä¸”æ‚ä¹± -> æ¨¡å‹æ²¡è®­ç»ƒå¥½æˆ– Temperature å¤ªé«˜")
    print("ğŸ‘‰ æ­£å¸¸æƒ…å†µä¸‹ï¼Œåº”è¯¥æ˜¯ä¸€ç»„æœ‰è§„å¾‹å˜åŒ–çš„æ•´æ•°ã€‚")

if __name__ == "__main__":
    main()